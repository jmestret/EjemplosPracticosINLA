---
title: "Documento Colaborativo: Ejemplos Prácticos de Modelos Bayesianos con INLA en R"
date: "Diciembre de 2023"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Introducción

En este documento, exploraremos diferentes modelos ajustados tanto en el enfoque frecuentista como en el bayesiano utilizando INLA y MCMC (JAGS, WinBUGS...). Empecemos cargando los paquetes necesarios para realizar los ejemplos.

```{r}
# Cargar paquetes
library(INLA)
library(jagsUI)
library(R2WinBUGS)
library(sf)

library(tidyverse)
library(gridExtra)
library(flextable)
library(fields)
```

# Datos Bernoulli {.tabset}

Para contextualizar nuestro análisis, consideramos un conjunto de datos obtenido de un estudio en Galicia sobre **Fasciola hepatica** en granjas de vacuno. El objetivo es analizar la presencia o ausencia del parásito en 200 granjas de vacuno en Galicia.

```{r}
# Cargar y explorar datos
datos <- read.csv("datos/granjas.csv", header = TRUE, row.names = 1)
colnames(datos) <- c("InfFasc", "Aptitud", "Permeabilidad", "Temperatura", "Edad")
datos$InfFasc <- as.factor(datos$InfFasc) 
datos$Aptitud <- as.factor(datos$Aptitud)
datos$Permeabilidad <- as.factor(datos$Permeabilidad)

# Resumen de los datos
summary(datos)

# Convertir InfFasc a numérico para el modelo
datos$InfFasc <- as.numeric(as.character(datos$InfFasc))
```

- **Variable respuesta**: $Y_i$ es la variable indicadora de presencia (1) o ausencia (0) de parásito en las $i = 1, ..., 200$ granjas analizadas.

- **Variables explicativas**: La aptitud productiva de la granja (categórica nominal con dos niveles, cárnica (C) o lechera (L)), la temperatura media anual de la granja (variable cuantitativa y continua), la edad media de las vacas de la granja (variable cuantitativa y continua) y la permeabilidad del suelo (variable categórica y ordinal con tres niveles, baja (1), media (2) y alta (3)).

- Como la presencia del parásito es  una variable indicadora binaria de tipo categórica nominal, se distribuye Bernoulli de parámetro $\pi_i$ (probabilidad de que el ganado de una granja $i$ esté infectado):

$$
Y_i \sim Ber(\pi_i), \quad i = 1, ..., 200
$$

- Utilizamos la transformación logit para relacionar el predictor lineal con la respuesta media:

$$
log \Big( \frac{\pi_i}{1 - \pi_i} \Big) = logit(\pi_i) = \beta_0 + \beta_1 X^{(1)}_i + \beta_2 (X^{(1)}_i)^2 + \beta_3 X^{(2)}_i + \gamma_{j(i)} + \delta_{k(i)}
$$

- El predictor lineal consiste de un intercepto $\beta_0$, una covariable edad $X^{(1)}_i$ , la temperatura del suelo $X^{(2)}_i$, un factor fijo aptitud de la granja $\gamma_{j(i)}$ con dos niveles (cárnica γ1 = 0 o lechera γ1) y otra variable categórica ordinal $\delta_{k(i)}$ (permeabilidad baja $\delta_{1}$ = 0, media $\delta_{2}$ y alta $\delta_{3}$).

> ℹ️ El modelo final utilizado fue obtenido después de la selección de variables realizada en la Tarea 2 de la asignatura de GLM. Más adelante, introduciremos un ejemplo para comparar modelos en INLA.

## Frecuentista

```{r}
# Ajustar modelo frecuentista
mod_freq <- glm(InfFasc ~ Edad + I(Edad^2) + Temperatura + Aptitud + Permeabilidad,
                data = datos, family = binomial(link = logit))

# Resumen del modelo
summary(mod_freq)
```

## Bayesiano con  INLA

- Priors de $\beta_0$ y $\beta_j$ en términos de precisión en lugar de sd:

$$
\beta_0 \sim N(0, \tau_{\beta_0} = 0), \quad \beta_j \sim N(0, \tau_{\beta_j} = 0.001), \quad j = 1,2,3
$$

```{r}
# Ajustar modelo bayesiano con INLA
mod_inla <- inla(InfFasc ~ 1 + Edad + I(Edad^2) + Temperatura + Aptitud + Permeabilidad,
                 data=datos, family = "binomial",
                 control.family = list(link = "logit"))

# Resumen del modelo
summary(mod_inla)
```

## Bayesiano con JAGS

<!--Con fines didácticos he recurrido a esta trampa (https://stackoverflow.com/a/54896392) ya que JAGS a veces presenta problemas con el logit a la hora de calcular el ratio-->

```{r, eval = FALSE}
cat(file="modelos/modelo_granjas.txt", "model{
    # Verosimilitud
    for (i in 1:n) {
        y[i] ~ dbern(p[i])
        logit(p[i]) <- beta0 +
                        beta1 * edad[i] + 
                        beta2* edad[i]^2 + 
                        beta3 * temperatura[i] +
                        gamma[aptitud[i]] + 
                        delta[permeabilidad[i]]
    }
    
    # Distributiones previas
    beta0 ~ dnorm(0, 0.001) # En INLA tau = 0
    beta1 ~ dnorm(0, 0.001)
    beta2 ~ dnorm(0, 0.001)
    beta3 ~ dnorm(0, 0.001)
    gamma[1] <- 0 # Corner constrain
    gamma[2] ~ dnorm(0, 0.001)
    delta[1] <- 0 # Corner constrain
    delta[2] ~ dnorm(0, 0.001)
    delta[3] ~ dnorm(0, 0.001)
}")

datos.granjas <- list(
  y = datos$InfFasc, edad = datos$Edad,
  temperatura = datos$Temperatura,
  aptitud = as.numeric(datos$Aptitud),
  permeabilidad = as.numeric(datos$Permeabilidad),
  n = nrow(datos)
)

iniciales.granjas <- function(){
  list(beta0 = rnorm(1), beta1 = rnorm(1),
       beta2 = rnorm(1), beta3 = rnorm(1),
       gamma = c(NA, rnorm(1)),
       delta = c(NA, rnorm(1), rnorm(1)))
}

parametros.granjas <- c("beta0", "beta1", "beta2",
                        "beta3", "gamma", "delta")

set.seed(123)
mod_jags <- jags(data = datos.granjas,
                 inits = iniciales.granjas,
                 parameters = parametros.granjas, 
                 model = "modelos/modelo_granjas.txt",
                 n.iter = 50000, n.burnin = 1000,
                 n.chains = 3)
save(mod_jags, file = "modelos/mcmc_granjas.RData")
```
```{r}
load("modelos/mcmc_granjas.RData")
# Resumen de los resultados
mod_jags$summary
```

# {.unlisted .unnumbered}

**Comparación**

Hemos realizado inferencia sobre el modelo mediante los enfoques Clásico y Bayesiano. Además, dentro de la inferencia Bayesiana, hemos utilizado un método de simulación asintóticamente exacto como MCMC y una aproximación numérica que es INLA. A continuación, compararemos los resultados de los modelos para observar que los resultados alcanzados son prácticamente idénticos.

> ⚠️ **Ojo**: Al comparar modelos en WinBUGS/JAGS con INLA porque no siempre las previas son las mismas. Mientras que en WinBUGS definimos las previas explicitament, en INL,A si ponemos nada, utiliza unas por defecto que debemos conocer (arriba las hemos definido).

Observamos que las distribuciones a posteriori de los parámetros obtenidas con JAGS y con INLA son prácticamente idénticas.

```{r class.source = 'fold-hide'}
# Visualización de resultados
jags_list <- list(mod_jags$sims.list$beta0,
                  mod_jags$sims.list$beta1,
                  mod_jags$sims.list$beta2,
                  mod_jags$sims.list$beta3,
                  mod_jags$sims.list$gamma[,2],
                  mod_jags$sims.list$delta[,2],
                  mod_jags$sims.list$delta[,3])
plist <- list()
for (i in 1:length(mod_inla$summary.fixed)){
  pgg <- ggplot() +
    geom_density(data = data.frame(x = jags_list[[i]]), aes(x), linewidth=1, color = "#4FA3AB", linetype = "dashed") +
    geom_line(data = data.frame(inla.smarginal(mod_inla$marginals.fixed[[i]])), aes(x, y), linewidth = 1, color = "#F6733A", linetype = "dashed") +
    ggtitle(names(mod_inla$marginals.fixed)[i]) +
    theme_bw()
  
  plist[[i]] <- pgg
}

n <- length(plist)
nCol <- ceiling(sqrt(n))
do.call("grid.arrange", c(plist, ncol=nCol, top = "JAGS: Azul, INLA: Naranja"))
```

Si observamos las estimaciones de los parámetros y las comparamos con la inferencia frecuentista, vemos que tenemos resultados muy similares, pero con la ventaja en el enfoque bayesiano de que tenemos una distribución para cada uno de ellos.

```{r class.source = 'fold-hide'}
# Comparación de resultados
params <- cbind(cbind(summary(mod_freq)$coefficients[,1], confint(mod_freq)),
                mod_jags$summary[c(1:4, 6, 8, 9), c(1,3,7)],
                mod_inla$summary.fixed[, c(1, 3, 5)])
colnames(params) <- paste0(rep(c("Frecuentista_", "JAGS_", "INLA_"), each = 3), c("est/mean", "2.5%", "97.5%"))

header_df <- tibble(key = colnames(params)) %>% 
  separate(col = key, into = c("Group1", "Group2"), sep = "_", remove = FALSE, fill = "left")

params %>% 
  mutate(across(where(is.numeric), round, 2)) %>% 
  rownames_to_column("Coefficients") %>% 
  flextable() %>% 
  set_header_df(mapping = header_df, key = "key") %>% 
  merge_h(part = "header") %>% 
  theme_booktabs() |>
  add_footer_lines("Nota: En el enfoque frecuentista, se presentan intervalos de confianza, mientras que en el enfoque bayesiano, se presentan intervalos de credibilidad")
```


# Modelo Poisson con Offset {.tabset}

En este ejemplo, exploraremos un modelo Poisson con offset utilizando un conjunto de datos que registra el número de quejas dirigidas al personal sanitario en un servicio de urgencias. El objetivo principal es estimar un modelo que explique la relación entre las quejas y las variables analizadas.

Las variables explicativas que consideraremos son las siguientes:

- **Número de consultas**: Una variable cuantitativa y discreta que representa la cantidad de consultas realizadas.

- **Residente**: Una variable categórica nominal con dos niveles, sí y no, que indica si el personal sanitario ha sido residente en el servicio de urgencias.

- **Sexo**: Una variable categórica ordinal dicotómica, clasificando al personal sanitario como hombre (H) o mujer (M).

- **Ingresos**: Una variable cuantitativa y continua que representa los ingresos asociados al personal sanitario.

- **Horas**: El número de horas de trabajo realizadas, una variable cuantitativa y continua.

Consideramos un modelo donde $\mu_i$ es el número medio de quejas por médico y $\lambda_i / Z_i$ representa la tasa del número de quejas $\lambda_i$ corregido por las consultas realizadas $Z_i$ (*offset*).

\begin{align*}
  Y_i \sim & Po(\mu_i), \quad i = 1, ..., 44, \\
  log(\mu_i) = & log(Z_i) + log(\lambda_i) = log(Z_i) + \beta_0 + \beta_1  horas + \beta_2 ingresos \\
              & + \beta_3 residentes + \beta_4 sexo
\end{align*}


Comenzamos cargando el conjunto de datos:

```{r}
datos <- read.table("datos/quejas.dat", header = T, sep="", stringsAsFactors = T)
```

Una parte crucial del análisis estadístico es la selección del modelo adecuado. En este caso, utilizaremos el enfoque bayesiano implementado en el paquete `INLA.` Para realizar la selección de modelos de manera eficiente en `INLA`, aprovechamos la opción `control.compute` al llamar a la función `inla()`. Esta opción nos permite calcular diversos criterios, como `cpo`, `dic`, `waic`... Puedes obtener más detalles sobre estos criterios y otras opciones [aquí](https://becarioprecario.bitbucket.io/inla-gitbook/ch-INLA.html#sec:modelassess).

Aunque existen paquetes que ofrecen funciones similares al método `step` que ya hemos empleado en el enfoque clásico, realizaremos una selección rápida de modelos en INLA. Comenzamos ajustando un modelo que incluye todas las covariables y el *offset*. La introducción del *offset* en INLA es similar a la función `glm()` y se puede especificar mediante el argumento `E` en la función `inla()` o incluirlo en la fórmula del modelo.

```{r}
# Modelo inicial con todas las covariables y offset
mod_inla1 <- inla(quejas ~ offset(log(consultas)) + horas + ingresos + residente + sexo,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

# Resumen del modelo inicial
mod_inla1$summary.fixed
```

En este punto, hemos ajustado un modelo inicial que incluye todas las covariables relevantes y el offset. El siguiente paso implica la evaluación de este modelo mediante criterios como el DIC, WAIC y CPO, que nos proporcionan información valiosa sobre su ajuste y complejidad. Este enfoque nos permite realizar una selección preliminar de variables antes de avanzar en el análisis.

En este resumen, observamos que las variables sexo y residente tienen intervalos de credibilidad amplios que incluyen el cero. Dado que el factor sexo parece no tener mucha importancia en presencia de otras variables, ajustaremos el modelo sin esta variable y compararemos el DIC y WAIC.

```{r}
mod_inla2 <- inla(quejas ~ offset(log(consultas)) + horas + ingresos + residente ,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

c(mod_inla1$dic$dic, mod_inla2$dic$dic)
```

La comparación muestra que el DIC disminuye al eliminar la variable sexo, aunque la reducción es mínima. Sin embargo, el nuevo modelo es más simple y parsimonioso, manteniendo un ajuste similar.

Continuamos explorando diferentes combinaciones de variables y posibles interacciones. Ajustamos varios modelos adicionales y evaluamos utilizando los criterios DIC, WAIC y CPO.

```{r}
# Modelos adicionales
mod_inla3 <- inla(quejas ~ offset(log(consultas)) + ingresos + residente,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

mod_inla4 <- inla(quejas ~ offset(log(consultas)) + horas + ingresos,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

mod_inla5 <- inla(quejas ~ offset(log(consultas)) + horas + ingresos + residente + horas:residente,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

mod_inla6 <- inla(quejas ~ offset(log(consultas)) + horas + residente + horas:residente,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))
```

En la siguiente tabla se resumen los valores de DIC, WAIC y CPO para los modelos ajustados. Observamos que, aunque hay pocas diferencias notables entre muchos de ellos, el modelo 6 es uno de los más simples y parsimoniosos, mostrando valores bajos en los tres criterios. Esto sugiere que el modelo 6 podría ser una elección adecuada para nuestro análisis.

```{r class.source = 'fold-hide'}
# Resumen de los valores de DIC, WAIC y CPO para los modelos ajustados
d <- data.frame(Modelo = c("log(E)+H+I+R+S", "log(E)+H+I+R", "log(E)+I+R", "log(E)+H+I", "log(E)+H+I+R+H:R", "log(E)+H+R+H:R"),
  DIC = c(mod_inla1$dic$dic, mod_inla2$dic$dic, mod_inla3$dic$dic, mod_inla4$dic$dic, mod_inla5$dic$dic, mod_inla6$dic$dic),
  WAIC = c(mod_inla1$waic$waic, mod_inla2$waic$waic, mod_inla3$waic$waic, mod_inla4$waic$waic, mod_inla5$waic$waic, mod_inla6$waic$waic),
  CPO = c(-sum(log(mod_inla1$cpo$cpo)), -sum(log(mod_inla2$cpo$cpo)), -sum(log(mod_inla3$cpo$cpo)), -sum(log(mod_inla4$cpo$cpo)), -sum(log(mod_inla5$cpo$cpo)), -sum(log(mod_inla6$cpo$cpo)))
)

knitr::kable(d, booktabs = TRUE,
  caption = "Resumen de los valores de DIC, WAIC y CPO para los modelos ajustados.")
```

Seleccionar el modelo adecuado va más allá de simplemente comparar criterios. Es esencial llevar a cabo una validación adicional, como el análisis de residuos, para asegurar la idoneidad del modelo elegido. 

A continuación, presentamos el modelo final y el código para ajustarlo tanto en el enfoque clásico como en los enfoques bayesianos con JAGS e INLA:

\begin{align*}
  Y_i \sim & Po(\mu_i), \quad i = 1, ..., 44, \\
  log(\mu_i) = & log(Z_i) + log(\lambda_i) = log(Z_i) + \beta_0 + \beta_1  horas + \beta_2 residentes \\
              & + \beta_3 horas:residentes
\end{align*}

## Frecuentista


```{r}
mod_freq <- glm(quejas ~ offset(log(consultas)) + horas + residente + horas:residente
                ,data = datos, family = poisson())
```


## Bayesiana en INLA

```{r}
mod_inla <- inla(quejas ~ offset(log(consultas)) + horas + residente + horas:residente,
                 data = datos, family = "poisson")
```


## Bayesiano con JAGS

```{r, eval = FALSE}
cat(file="modelos/modelo_quejas.txt", "model{
    # Verosimilitud
    for (i in 1:n) {
        y[i] ~ dpois(mu[i])
        log(mu[i]) = beta0 + beta1 * horas[i] + beta2[residente[i]] + beta3[residente[i]]*horas[i]
    }
    
    # Distributiones previas
    beta0 ~ dnorm(0, 0.001)
    beta1 ~ dnorm(0, 0.001)
    beta2[1] <- 0 # Corner constrain
    beta2[2] ~ dnorm(0, 0.001)
    beta3[1] <- 0 # Corner constrain
    beta3[2] ~ dnorm(0, 0.001)
}")

datos.quejas <- list(
  y = datos$quejas, horas = datos$horas,
  residente = as.numeric(datos$residente),
  E = datos$consultas,
  n = nrow(datos)
)

iniciales.quejas <- function(){
  list(beta0 = rnorm(1), beta1 = rnorm(1),
       beta2 = c(NA, rnorm(1)),
       beta3 = c(NA, rnorm(1)))
}

parametros.quejas <- c("beta0", "beta1",
                        "beta3", "beta4")

set.seed(123)
mod_jags <- jags(data = datos.quejas,
                 inits = iniciales.quejas,
                 parameters = parametros.quejas, 
                 model = "modelos/modelo_quejas.txt",
                 n.iter = 10000, n.burnin = 1000,
                 n.chains = 3)
```

# Simulacion de datos espaciales I

En este ejemplo, abordaremos la simulación de datos espaciales, asumiendo que las realizaciones provienen de un campo espacial con cierta dependencia espacial. La idea fundamental es que las observaciones cercanas en el espacio serán más similares entre sí. La similitud entre las localizaciones estará relacionada con la distancia espacial.

## Simulación de los datos {.tabset}

Primero, generaremos las **localizaciones de los puntos**. Hay varias maneras de hacerlo, como generar puntos aleatorios en un dominio cuadrado, asignar densidades de puntos diferentes en áreas específicas o generar puntos dentro de un polígono.

```{r}
n <- 200 # Número de observaciones
semilla <- 2023
```


### Puntos aleatorios en un dominio cuadrado

```{r}
set.seed(semilla)
coords_rand <- cbind(long = sample(1:n), lat = sample(1:n))
```
```{r class.source = 'fold-hide'}
ggplot(data.frame(coords_rand), aes(x = long, y = lat)) +
  geom_point() + 
  theme_bw() +
  coord_fixed(ratio = 1)
```


### Puntos con mayor densidad en la esquina inferior izquierda

```{r}
set.seed(semilla)
coords_group <- cbind(long = sample(1:n / n - 0.5 / n)^2, lat = sample(1:n / n - 0.5 / n)^2)
```
```{r class.source = 'fold-hide'}
ggplot(data.frame(coords_group), aes(x = long, y = lat)) +
  geom_point() + 
  theme_bw() +
  coord_fixed(ratio = 1)
```

### Puntos aleatorios de un polígono

```{r results='hide'}
# Cargar polígono
nc <- st_read(system.file("shape/nc.shp", package="sf"))
nc <- st_union(nc)

# Generar localizaciones
set.seed(semilla)
points <- st_sample(nc, size = n)
```
```{r class.source = 'fold-hide'}
ggplot() + 
  geom_sf(data = nc) + 
  geom_sf(data = points) +
  theme_bw()
```

## {.unlisted .unnumbered}

La dependencia espacial entre los puntos se puede definir mediante una estructura de covarianza Matern. La función de correlación Matern tiene dos parámetros: el parámetro de escala $\kappa$ y el parámetro de suavizado $\nu$. Puedes encontrar una explicación detallada de la función de correlación Matern [aquí](https://becarioprecario.bitbucket.io/spde-gitbook/ch-intro.html#sec:matern).

$$
\text{Corr}(d) = \frac{1}{2^{\nu-1}\Gamma(\nu)} (\kappa d)^{\nu} K_{\nu}(\kappa d), \quad \alpha = \nu + \frac{d}{2},
$$
donde $K_{\nu}$ es la función de Bessel modificada y $\Gamma(\cdot)$ es la función Gamma. El rango está definido como $r = \sqrt{8\nu} / \kappa$, aproximadamente la distancia donde la función de covarianza llega a ser cerca de 0.1.

Los hiperparámetros son el parámetro de precisión $\tau$ y el rango $r$, $\theta = (\tau, r)$. El campo latente tiene una varianza marginal de $\frac{1}{\tau}$ y un rango (definido como se mencionó anteriormente) de $r$. Se representan internamente como $(\text{log} \tau, \text{log} r)$.

La matriz de covarianza Matern es

$$
\Sigma_{i,j} = \sigma_u Cor_M(X(s_i), X(s_j))
$$

Para este ejemplo vamos a utilizar las localizaciones generadas aleatoriamente. Observamos que la posición de las localizaciones en los ejes x e y se mueve entre 0 y 200. Los parámetros que vamos a utilizar para la covarianza Matern se eligen en consecuencia. Dada las localizaciones de los puntos (entre 0 y 200) , elegiremos un rango del efecto espacial de 100. Utilizando $\nu = 1$ y a partir de esta realción $r = \sqrt{8\nu} / \kappa$, podemos obtener el valor de $\kappa = 0.02828427$. Le pondremos una varianza de $\sigma^2_u = 2$ al efecto espacial.

Ahora bien, el valor observado en las localizaciones ($_i$), a parte efecto espacial subyacente, tendrá adicionalmente un error de medición ($e_i$) que asumimos independiente y normalmente distribuido: 

$$
y(s_i) = x(s_i) + e_i \quad e_i \sim N(0, \sigma_e^2),
$$
donde $\sigma_e^2$ es el efecto de la pepita. Por eso, tenemos una covarianza $\sigma_e^2 \mathbf{I} + \Sigma$. Definiremos un intercepto de $\beta_0 = 10$ y una semilla (error experimental) de $\sigma^2_e = 0.5$.

```{r}
rango <- 100
nu <- 1
kappa <- sqrt((8*nu))/rango
beta0 <- 10
sigma2e <- 0.5
sigma2u <- 2

dmat <- as.matrix(dist(coords_rand)) # Matriz distancias
```

> ⚠️ Es importante seleccionar un rango adecuado de acuerdo al tamaño y unidades de medida de la zona de estudio.

```{r}
mcor <- ifelse(dmat > 0, besselK(dmat * kappa, nu) * (dmat * kappa)^nu / (gamma(nu) * 2^(nu - 1)), 1)
mcor[1:5, 1:5]

mcov <- sigma2e * diag(nrow(mcor)) + sigma2u * mcor
```

Finalmente, simulamos los valores de nuestra variable respuesta en las localizaciones:

```{r}
R <- chol(mcov) # Descomposición de Cholesky
set.seed(semilla)
y <- beta0 + drop(rnorm(n) %*% R)

datos <- data.frame(long = coords_rand[,1],
                    lat = coords_rand[,2],
                    y = y)
```
```{r class.source = 'fold-hide'}
ggplot(datos, aes(x = long, y = lat)) +
  geom_point(size = y/2) +
  theme_bw() +
  coord_fixed(ratio = 1)
```

## Ajuste del modelo geoestadístico con INLA

Utilizando los datos simulados, vamos a ajustar un modelo geoestadístico con INLA. Para ello, definiremos un modelo SPDE. Dadas $n$ observaciones $y_i$, $i = 1,...n$ en las localizaciones $s_i$, definimos el siguiente modelo geoestadístico sencillo:

$$
\mathbf{y} | \beta_0, \mathbf{u}, \sigma_e^2 \sim N(\beta_0 + \mathbf{Au}, \sigma_e^2),
$$
donde $\beta_0$ es el intercepto, $\mathbf{A}$ es la matriz de proyección, y $\mathbf{u}$ es un campo aleatorio gaussiano espacial. La matriz de proyección $\mathbf{A}$ conecta el campo aleatorio Gaussiano con las localizaciones observadas de los datos.

Al crear un mesh, es crucial asegurarse de que cubra todo el dominio espacial de interés. Podemos definir el siguiente mesh basado en las localizaciones (las localizaciones se dispondrán en los vértices en este caso):
```{r}
mesh <- inla.mesh.2d(coords_rand, max.edge = c(30, 50))
```
```{r class.source = 'fold-hide'}
plot(mesh)
points(coords_rand, col = "red", pch = 16)
```

> ℹ️ La sección X proporciona más detalles sobre cómo construir un mesh (HACER ESTO). Además, se puede obtener más información [aquí](https://becarioprecario.bitbucket.io/spde-gitbook/ch-intro.html#sec:mesh)

El modelo SPDE se puede definir con la función `inla.spde2.matern()`, que utiliza los argumentos `mesh` y `alpha` relacionados con la suavización del parámetro. Esta parametrización es flexible y permite controlar los parámetros definiendo la desviación estándar marginal y el rango. También podríamos definirla utilizando las [PC-priors](https://becarioprecario.bitbucket.io/spde-gitbook/ch-INLA.html#sec:intropc) mediante la función `inla.spde2.pcmatern()`.

Una forma de definir estas priors sería representar el variograma y seleccionar priors para el rango. Como hemos simulado y conocemos el valor, no lo representaremos esta vez. Además, también es interesante realizar un análisis de sensibilidad para observar cómo varían los resultados al utilizar diferentes priors (ya os adelanto que no es particularmente robusto).

```{r}
spde <- inla.spde2.pcmatern(
  # Mesh and smoothness parameter
  mesh = mesh, alpha = 2,
  # P(practic.range < 50) = 0.1
  prior.range = c(50, 0.1),
  # P(sigma > 5) = 0.1
  prior.sigma = c(5, 0.1)) 
```

Esta parte de generar el mesh y el modelo SPDE puede ser un poco compleja. En este [enlace](https://becarioprecario.bitbucket.io/spde-gitbook/ch-intro.html#sec:spde), encontrarás una explicación más detallada.

## Matriz de proyección

El modelo SPDE se define en un mesh de dimensión $m$, mientras que la variable respuesta está definida en $n$ localizaciones. Para establecer una conexión entre los $m$ vértices del mesh y las $n$ localizaciones, empleamos una matriz de proyección $\mathbf{A}$. El valor de cualquier punto se crea proyectando dicho punto sobre un plano formado por el triángulo en el que se encuentra. El valor exacto del punto es la media ponderada de tres pesos asociados a cada vértice.

```{r}
A <- inla.spde.make.A(mesh, loc = coords_rand)
```

La matriz tiene una dimensión igual al número de datos en las localizaciones por el número de vértices del mesh:
```{r}
dim(A)
```

## Ajuste del modelo

Para ajustar un modelo SPDE en INLA, primero debemos organizar los datos en un stack. Esta función permite ordenar los elementos importantes para definir un modelo SPDE. Los elementos clave del stack son: una lista con los vectores de datos, una lista con las matrices de proyección y una lista con los efectos.

```{r}
stack <- inla.stack(
  data = list(y = datos$y),
  A = list(A, 1),
  effects = list(i = 1:spde$n.spde,
                 beta0 = rep(1, nrow(datos))),
  tag = "est"
)
```

Al ajustar el modelo, debemos eliminar el intercepto de la fórmula e incluirlo como una covariable para que todos los efectos se incluyan en la matriz de proyección.

```{r}
res <- inla(y ~ 0 + beta0 + f(i, model = spde),
            data = inla.stack.data(stack),
            control.predictor = list(A = inla.stack.A(stack)))
```

Recordemos que al simular, definimos los siguientes parámetros:

- $\beta_0$ = 10
- $\sigma^2_e$ = 0.5
- $\sigma^2_u$ = 2
- Rango = 100
- $\nu$ = 1

Y observamos que podemos recuperar los parámetros definidos:

```{r}
# Intercepto
res$summary.fixed

# Hiperparámetros
res$summary.hyperpar

# Convertimos la precisión en desviación
post.se <- inla.tmarginal(function(x) sqrt(1 / exp(x)),
                          res$internal.marginals.hyperpar[[1]])
inla.emarginal(function(x) x, post.se)
inla.hpdmarginal(0.95, post.se)
```
```{r class.source = 'fold-hide'}
plot(post.se, type = "l", xlab = "st. deviation", 
     ylab = "density", main = "Standard deviation")
```

## Proyección del campo aleatorio y predicciones

Un objetivo principal al trabajar con modelos espaciales es visualizar el campo aleatorio. Utilizando la función `inla.mesh.projector()`, generaremos una matriz de proyección sobre un grid de puntos que cubre nuestro mesh.

```{r}
grid.projector <- inla.mesh.projector(
  mesh,
  xlim = c(0, 200), ylim = c(0, 200),
  dims = c(101, 101)
)
```

A continuación, podemos obtener la media y desviación a posteriori del efecto espacial basándonos en la idea del mesh, donde cada punto se interpola utilizando esa matriz de proyección y para cada punto (fila de la matriz), tenemos el peso de los tres vértices del triángulo del mesh donde se encuentra:

```{r}
prd0.m <- inla.mesh.project(grid.projector,
                            res$summary.random$i$mean)
prd0.s <- inla.mesh.project(grid.projector,
                            res$summary.random$i$sd)
```

Por otro lado, otra cantidad de interés es el valor esperado en las localizaciones que no hemos observado. Considerando que
$$
\mathbf{y} \sim N(\mu = \mathbf{1}\beta_0 + \mathbf{Au}, \sigma_ e^2 \mathbf{I}),
$$
vamos a querer predecir la media y desviación en diferentes localizaciones, es decir, la distribución a posteriori de $\mu$.

Para ello, debemos crear un escenario de predicción. Crearemos dos stacks, uno que represente los datos observados y otro las predicciones (con NA en la respuesta). Estos stacks se juntarán en un mismo stack.

```{r}
stack_pred <- inla.stack(
  data = list(y = NA),
  A = list(grid.projector$proj$A, 1),
  effects = list(i = 1:spde$n.spde,
                 beta0 = rep(1, nrow(grid.projector$proj$A))),
  tag = "pred"
)

stack_all <- inla.stack(stack, stack_pred)

res.pred <- inla(y ~ 0 + beta0 + f(i, model = spde),
                 data = inla.stack.data(stack_all),
                 control.predictor = list(A = inla.stack.A(stack_all),
                                          compute = TRUE),
                 control.mode = list(theta = res$mode$theta,
                                     restart = FALSE),
                 quantiles = NULL)
```

Obtenemos los índices de los valores predichos:

```{r}
igr <- inla.stack.index(stack_all, 'pred')$data
```
```{r class.source = 'fold-hide'}
par(mfrow = c(2, 2))
image(x = grid.projector$x, y = grid.projector$y, z = prd0.m, main = "Media efecto espacial")
image(x = grid.projector$x, y = grid.projector$y, z =  matrix(res.pred$summary.fitted.values$mean[igr], 101), main = "Respuesta esperada")
image(x = grid.projector$x, y = grid.projector$y, z = prd0.s, main = "SD efecto espacial")
image(x = grid.projector$x, y = grid.projector$y, z =  matrix(res.pred$summary.fitted.values$sd[igr], 101), main = "SD mu")
```


<!--
https://becarioprecario.bitbucket.io/spde-gitbook/ch-intro.html#spde-model-definition

https://www.flutterbys.com.au/stats/tut/tut12.13.html

https://ourcodingclub.github.io/tutorials/spatial-modelling-inla/#increasecomplexity

https://becarioprecario.bitbucket.io/spde-gitbook/ch-manipula.html

https://rpubs.com/zs_sz/inla_spt

https://arxiv.org/pdf/2308.13928.pdf

https://www.tandfonline.com/doi/epdf/10.1080/10618600.2022.2144330?needAccess=true

http://ndl.ethernet.edu.et/bitstream/123456789/39269/1/K.%20Gerald%20van%20den.pdf

https://groups.google.com/g/r-inla-discussion-group/c/4XvtueZLvJY/m/0EKbia8zAwAJ
-->
