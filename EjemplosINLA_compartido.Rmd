---
title: "Documento Colaborativo: Ejemplos Prácticos de Modelos Bayesianos con INLA en R"
author: "Jorge Mestre, Juan Vitoria, Silvia Rasero"
date: "Diciembre de 2023"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Introducción

En este documento, exploraremos diferentes modelos ajustados tanto en el enfoque frecuentista como en el bayesiano utilizando INLA y MCMC (JAGS, WinBUGS...). Empecemos cargando los paquetes necesarios para realizar los ejemplos.

```{r}
# Cargar paquetes
library(INLA)
library(jagsUI)
library(R2WinBUGS)
library(sf)
library(vctrs)
library(tidyr)
library(tidyverse)
library(gridExtra)
library(flextable)
library(fields)
library(dplyr)
library(glmm)
```

# Datos Bernoulli {.tabset}

Para contextualizar nuestro análisis, consideramos un conjunto de datos obtenido de un estudio en Galicia sobre *Fasciola hepatica* en granjas de vacuno. El objetivo es analizar la presencia o ausencia del parásito en 200 granjas de vacuno en Galicia.

```{r}
# Cargar y explorar datos
datos <- read.csv("datos/granjas.csv", header = TRUE, row.names = 1)
colnames(datos) <- c("InfFasc", "Aptitud", "Permeabilidad", "Temperatura", "Edad")
datos$InfFasc <- as.factor(datos$InfFasc) 
datos$Aptitud <- as.factor(datos$Aptitud)
datos$Permeabilidad <- as.factor(datos$Permeabilidad)

# Resumen de los datos
summary(datos)

# Convertir InfFasc a numérico para el modelo
datos$InfFasc <- as.numeric(as.character(datos$InfFasc))
```

- **Variable respuesta**: $Y_i$ es la variable indicadora de presencia (1) o ausencia (0) de parásito en las $i = 1, ..., 200$ granjas analizadas.

- **Variables explicativas**: La aptitud productiva de la granja (categórica nominal con dos niveles, cárnica (C) o lechera (L)), la temperatura media anual de la granja (variable cuantitativa y continua), la edad media de las vacas de la granja (variable cuantitativa y continua) y la permeabilidad del suelo (variable categórica y ordinal con tres niveles, baja (1), media (2) y alta (3)).

- Como la presencia del parásito es  una variable indicadora binaria de tipo categórica nominal, se distribuye Bernoulli de parámetro $\pi_i$ (probabilidad de que el ganado de una granja $i$ esté infectado):

$$
Y_i \sim Ber(\pi_i), \quad i = 1, ..., 200
$$

- Utilizamos la transformación logit para relacionar el predictor lineal con la respuesta media:

$$
log \Big( \frac{\pi_i}{1 - \pi_i} \Big) = logit(\pi_i) = \beta_0 + \beta_1 X^{(1)}_i + \beta_2 (X^{(1)}_i)^2 + \beta_3 X^{(2)}_i + \gamma_{j(i)} + \delta_{k(i)}
$$

- El predictor lineal consiste de un intercepto $\beta_0$, una covariable edad $X^{(1)}_i$ , la temperatura del suelo $X^{(2)}_i$, un factor fijo aptitud de la granja $\gamma_{j(i)}$ con dos niveles (cárnica γ1 = 0 o lechera γ1) y otra variable categórica ordinal $\delta_{k(i)}$ (permeabilidad baja $\delta_{1}$ = 0, media $\delta_{2}$ y alta $\delta_{3}$).

> ℹ️ El modelo final utilizado fue obtenido después de la selección de variables realizada en la Tarea 2 de la asignatura de GLM. Más adelante, introduciremos un ejemplo para comparar modelos en INLA.

## Frecuentista

```{r}
# Ajustar modelo frecuentista
mod_freq <- glm(InfFasc ~ Edad + I(Edad^2) + Temperatura + Aptitud + Permeabilidad,
                data = datos, family = binomial(link = logit))

# Resumen del modelo
summary(mod_freq)
```

## Bayesiano con  INLA

- Priors de $\beta_0$ y $\beta_j$ en términos de precisión en lugar de sd:

$$
\beta_0 \sim N(0, \tau_{\beta_0} = 0), \quad \beta_j \sim N(0, \tau_{\beta_j} = 0.001), \quad j = 1,2,3
$$

```{r}
# Ajustar modelo bayesiano con INLA
mod_inla <- inla(InfFasc ~ 1 + Edad + I(Edad^2) + Temperatura + Aptitud + Permeabilidad,
                 data=datos, family = "binomial",
                 control.family = list(link = "logit"))

# Resumen del modelo
summary(mod_inla)
```

## Bayesiano con JAGS

<!--Con fines didácticos he recurrido a esta trampa (https://stackoverflow.com/a/54896392) ya que JAGS a veces presenta problemas con el logit a la hora de calcular el ratio-->

```{r, eval = FALSE}
cat(file="modelos/modelo_granjas.txt", "model{
    # Verosimilitud
    for (i in 1:n) {
        y[i] ~ dbern(p[i])
        logit(p[i]) <- beta0 +
                        beta1 * edad[i] + 
                        beta2* edad[i]^2 + 
                        beta3 * temperatura[i] +
                        gamma[aptitud[i]] + 
                        delta[permeabilidad[i]]
    }
    
    # Distributiones previas
    beta0 ~ dnorm(0, 0.001) # En INLA tau = 0
    beta1 ~ dnorm(0, 0.001)
    beta2 ~ dnorm(0, 0.001)
    beta3 ~ dnorm(0, 0.001)
    gamma[1] <- 0 # Corner constrain
    gamma[2] ~ dnorm(0, 0.001)
    delta[1] <- 0 # Corner constrain
    delta[2] ~ dnorm(0, 0.001)
    delta[3] ~ dnorm(0, 0.001)
}")

datos.granjas <- list(
  y = datos$InfFasc, edad = datos$Edad,
  temperatura = datos$Temperatura,
  aptitud = as.numeric(datos$Aptitud),
  permeabilidad = as.numeric(datos$Permeabilidad),
  n = nrow(datos)
)

iniciales.granjas <- function(){
  list(beta0 = rnorm(1), beta1 = rnorm(1),
       beta2 = rnorm(1), beta3 = rnorm(1),
       gamma = c(NA, rnorm(1)),
       delta = c(NA, rnorm(1), rnorm(1)))
}

parametros.granjas <- c("beta0", "beta1", "beta2",
                        "beta3", "gamma", "delta")

set.seed(123)
mod_jags <- jags(data = datos.granjas,
                 inits = iniciales.granjas,
                 parameters = parametros.granjas, 
                 model = "modelos/modelo_granjas.txt",
                 n.iter = 50000, n.burnin = 1000,
                 n.chains = 3)
save(mod_jags, file = "modelos/mcmc_granjas.RData")
```
```{r}
load("modelos/mcmc_granjas.RData")
# Resumen de los resultados
mod_jags$summary
```

# {.unlisted .unnumbered}

**Comparación**

Hemos realizado inferencia sobre el modelo mediante los enfoques Clásico y Bayesiano. Además, dentro de la inferencia Bayesiana, hemos utilizado un método de simulación asintóticamente exacto como MCMC y una aproximación numérica que es INLA. A continuación, compararemos los resultados de los modelos para observar que los resultados alcanzados son prácticamente idénticos.

> ⚠️ **Ojo**: Al comparar modelos en WinBUGS/JAGS con INLA porque no siempre las previas son las mismas. Mientras que en WinBUGS definimos las previas explicitament, en INL,A si ponemos nada, utiliza unas por defecto que debemos conocer (arriba las hemos definido).

Observamos que las distribuciones a posteriori de los parámetros obtenidas con JAGS y con INLA son prácticamente idénticas.

```{r class.source = 'fold-hide'}
# Visualización de resultados
jags_list <- list(mod_jags$sims.list$beta0,
                  mod_jags$sims.list$beta1,
                  mod_jags$sims.list$beta2,
                  mod_jags$sims.list$beta3,
                  mod_jags$sims.list$gamma[,2],
                  mod_jags$sims.list$delta[,2],
                  mod_jags$sims.list$delta[,3])
plist <- list()
for (i in 1:length(mod_inla$summary.fixed)){
  pgg <- ggplot() +
    geom_density(data = data.frame(x = jags_list[[i]]), aes(x), linewidth=1, color = "#4FA3AB", linetype = "dashed") +
    geom_line(data = data.frame(inla.smarginal(mod_inla$marginals.fixed[[i]])), aes(x, y), linewidth = 1, color = "#F6733A", linetype = "dashed") +
    ggtitle(names(mod_inla$marginals.fixed)[i]) +
    theme_bw()
  
  plist[[i]] <- pgg
}

n <- length(plist)
nCol <- ceiling(sqrt(n))
do.call("grid.arrange", c(plist, ncol=nCol, top = "JAGS: Azul, INLA: Naranja"))
```

Si observamos las estimaciones de los parámetros y las comparamos con la inferencia frecuentista, vemos que tenemos resultados muy similares, pero con la ventaja en el enfoque bayesiano de que tenemos una distribución para cada uno de ellos.

```{r class.source = 'fold-hide'}
# Comparación de resultados
params <- cbind(cbind(summary(mod_freq)$coefficients[,1], confint(mod_freq)),
                mod_jags$summary[c(1:4, 6, 8, 9), c(1,3,7)],
                mod_inla$summary.fixed[, c(1, 3, 5)])
colnames(params) <- paste0(rep(c("Frecuentista_", "JAGS_", "INLA_"), each = 3), c("est/mean", "2.5%", "97.5%"))

header_df <- tibble(key = colnames(params)) %>% 
  separate(col = key, into = c("Group1", "Group2"), sep = "_", remove = FALSE, fill = "left")

params %>% 
  mutate(across(where(is.numeric), round, 2)) %>% 
  rownames_to_column("Coefficients") %>% 
  flextable() %>% 
  set_header_df(mapping = header_df, key = "key") %>% 
  merge_h(part = "header") %>% 
  theme_booktabs() |>
  add_footer_lines("Nota: En el enfoque frecuentista, se presentan intervalos de confianza, mientras que en el enfoque bayesiano, se presentan intervalos de credibilidad")
```


# Modelo Poisson con Offset {.tabset}

En este ejemplo, exploraremos un modelo Poisson con offset utilizando un conjunto de datos que registra el número de quejas dirigidas al personal sanitario en un servicio de urgencias. El objetivo principal es estimar un modelo que explique la relación entre las quejas y las variables analizadas.

Las variables explicativas que consideraremos son las siguientes:

- **Número de consultas**: Una variable cuantitativa y discreta que representa la cantidad de consultas realizadas.

- **Residente**: Una variable categórica nominal con dos niveles, sí y no, que indica si el personal sanitario ha sido residente en el servicio de urgencias.

- **Sexo**: Una variable categórica ordinal dicotómica, clasificando al personal sanitario como hombre (H) o mujer (M).

- **Ingresos**: Una variable cuantitativa y continua que representa los ingresos asociados al personal sanitario.

- **Horas**: El número de horas de trabajo realizadas, una variable cuantitativa y continua.

Consideramos un modelo donde $\mu_i$ es el número medio de quejas por médico y $\lambda_i / Z_i$ representa la tasa del número de quejas $\lambda_i$ corregido por las consultas realizadas $Z_i$ (*offset*).

\begin{align*}
  Y_i \sim & Po(\mu_i), \quad i = 1, ..., 44, \\
  log(\mu_i) = & log(Z_i) + log(\lambda_i) = log(Z_i) + \beta_0 + \beta_1  horas + \beta_2 ingresos \\
              & + \beta_3 residentes + \beta_4 sexo
\end{align*}


Comenzamos cargando el conjunto de datos:

```{r}
datos <- read.table("datos/quejas.dat", header = T, sep="", stringsAsFactors = T)
```

Una parte crucial del análisis estadístico es la selección del modelo adecuado. En este caso, utilizaremos el enfoque bayesiano implementado en el paquete `INLA.` Para realizar la selección de modelos de manera eficiente en `INLA`, aprovechamos la opción `control.compute` al llamar a la función `inla()`. Esta opción nos permite calcular diversos criterios, como `cpo`, `dic`, `waic`... Puedes obtener más detalles sobre estos criterios y otras opciones [aquí](https://becarioprecario.bitbucket.io/inla-gitbook/ch-INLA.html#sec:modelassess).

Aunque existen paquetes que ofrecen funciones similares al método `step` que ya hemos empleado en el enfoque clásico, realizaremos una selección rápida de modelos en INLA. Comenzamos ajustando un modelo que incluye todas las covariables y el *offset*. La introducción del *offset* en INLA es similar a la función `glm()` y se puede especificar mediante el argumento `E` en la función `inla()` o incluirlo en la fórmula del modelo.

```{r}
# Modelo inicial con todas las covariables y offset
mod_inla1 <- inla(quejas ~ offset(log(consultas)) + horas + ingresos + residente + sexo,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

# Resumen del modelo inicial
mod_inla1$summary.fixed
```

En este punto, hemos ajustado un modelo inicial que incluye todas las covariables relevantes y el offset. El siguiente paso implica la evaluación de este modelo mediante criterios como el DIC, WAIC y CPO, que nos proporcionan información valiosa sobre su ajuste y complejidad. Este enfoque nos permite realizar una selección preliminar de variables antes de avanzar en el análisis.

En este resumen, observamos que las variables sexo y residente tienen intervalos de credibilidad amplios que incluyen el cero. Dado que el factor sexo parece no tener mucha importancia en presencia de otras variables, ajustaremos el modelo sin esta variable y compararemos el DIC y WAIC.

```{r}
mod_inla2 <- inla(quejas ~ offset(log(consultas)) + horas + ingresos + residente ,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

c(mod_inla1$dic$dic, mod_inla2$dic$dic)
```

La comparación muestra que el DIC disminuye al eliminar la variable sexo, aunque la reducción es mínima. Sin embargo, el nuevo modelo es más simple y parsimonioso, manteniendo un ajuste similar.

Continuamos explorando diferentes combinaciones de variables y posibles interacciones. Ajustamos varios modelos adicionales y evaluamos utilizando los criterios DIC, WAIC y CPO.

```{r}
# Modelos adicionales
mod_inla3 <- inla(quejas ~ offset(log(consultas)) + ingresos + residente,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

mod_inla4 <- inla(quejas ~ offset(log(consultas)) + horas + ingresos,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

mod_inla5 <- inla(quejas ~ offset(log(consultas)) + horas + ingresos + residente + horas:residente,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

mod_inla6 <- inla(quejas ~ offset(log(consultas)) + horas + residente + horas:residente,
                 data = datos, family = "poisson",
                 control.predictor = list(compute = TRUE),
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))
```

En la siguiente tabla se resumen los valores de DIC, WAIC y CPO para los modelos ajustados. Observamos que, aunque hay pocas diferencias notables entre muchos de ellos, el modelo 6 es uno de los más simples y parsimoniosos, mostrando valores bajos en los tres criterios. Esto sugiere que el modelo 6 podría ser una elección adecuada para nuestro análisis.

```{r class.source = 'fold-hide'}
# Resumen de los valores de DIC, WAIC y CPO para los modelos ajustados
d <- data.frame(Modelo = c("log(E)+H+I+R+S", "log(E)+H+I+R", "log(E)+I+R", "log(E)+H+I", "log(E)+H+I+R+H:R", "log(E)+H+R+H:R"),
  DIC = c(mod_inla1$dic$dic, mod_inla2$dic$dic, mod_inla3$dic$dic, mod_inla4$dic$dic, mod_inla5$dic$dic, mod_inla6$dic$dic),
  WAIC = c(mod_inla1$waic$waic, mod_inla2$waic$waic, mod_inla3$waic$waic, mod_inla4$waic$waic, mod_inla5$waic$waic, mod_inla6$waic$waic),
  CPO = c(-sum(log(mod_inla1$cpo$cpo)), -sum(log(mod_inla2$cpo$cpo)), -sum(log(mod_inla3$cpo$cpo)), -sum(log(mod_inla4$cpo$cpo)), -sum(log(mod_inla5$cpo$cpo)), -sum(log(mod_inla6$cpo$cpo)))
)

knitr::kable(d, booktabs = TRUE,
  caption = "Resumen de los valores de DIC, WAIC y CPO para los modelos ajustados.")
```

Seleccionar el modelo adecuado va más allá de simplemente comparar criterios. Es esencial llevar a cabo una validación adicional, como el análisis de residuos, para asegurar la idoneidad del modelo elegido. 

A continuación, presentamos el modelo final y el código para ajustarlo tanto en el enfoque clásico como en los enfoques bayesianos con JAGS e INLA:

\begin{align*}
  Y_i \sim & Po(\mu_i), \quad i = 1, ..., 44, \\
  log(\mu_i) = & log(Z_i) + log(\lambda_i) = log(Z_i) + \beta_0 + \beta_1  horas + \beta_2 residentes \\
              & + \beta_3 horas:residentes
\end{align*}

## Frecuentista


```{r}
mod_freq <- glm(quejas ~ offset(log(consultas)) + horas + residente + horas:residente
                ,data = datos, family = poisson())
```


## Bayesiana en INLA

```{r}
mod_inla <- inla(quejas ~ offset(log(consultas)) + horas + residente + horas:residente,
                 data = datos, family = "poisson")
```


## Bayesiano con JAGS

```{r, eval = FALSE}
cat(file="modelos/modelo_quejas.txt", "model{
    # Verosimilitud
    for (i in 1:n) {
        y[i] ~ dpois(mu[i])
        log(mu[i]) = beta0 + beta1 * horas[i] + beta2[residente[i]] + beta3[residente[i]]*horas[i]
    }
    
    # Distributiones previas
    beta0 ~ dnorm(0, 0.001)
    beta1 ~ dnorm(0, 0.001)
    beta2[1] <- 0 # Corner constrain
    beta2[2] ~ dnorm(0, 0.001)
    beta3[1] <- 0 # Corner constrain
    beta3[2] ~ dnorm(0, 0.001)
}")

datos.quejas <- list(
  y = datos$quejas, horas = datos$horas,
  residente = as.numeric(datos$residente),
  E = datos$consultas,
  n = nrow(datos)
)

iniciales.quejas <- function(){
  list(beta0 = rnorm(1), beta1 = rnorm(1),
       beta2 = c(NA, rnorm(1)),
       beta3 = c(NA, rnorm(1)))
}

parametros.quejas <- c("beta0", "beta1",
                        "beta3", "beta4")

set.seed(123)
mod_jags <- jags(data = datos.quejas,
                 inits = iniciales.quejas,
                 parameters = parametros.quejas, 
                 model = "modelos/modelo_quejas.txt",
                 n.iter = 10000, n.burnin = 1000,
                 n.chains = 3)
```

# Simulacion de datos espaciales I

En este ejemplo, abordaremos la simulación de datos espaciales, asumiendo que las realizaciones provienen de un campo espacial con cierta dependencia espacial. La idea fundamental es que las observaciones cercanas en el espacio serán más similares entre sí. La similitud entre las localizaciones estará relacionada con la distancia espacial.

## Simulación de los datos {.tabset}

Primero, generaremos las **localizaciones de los puntos**. Hay varias maneras de hacerlo, como generar puntos aleatorios en un dominio cuadrado, asignar densidades de puntos diferentes en áreas específicas o generar puntos dentro de un polígono.

```{r}
n <- 200 # Número de observaciones
semilla <- 2023
```


### Puntos aleatorios en un dominio cuadrado

```{r}
set.seed(semilla)
coords_rand <- cbind(long = sample(1:n), lat = sample(1:n))
```
```{r class.source = 'fold-hide'}
ggplot(data.frame(coords_rand), aes(x = long, y = lat)) +
  geom_point() + 
  theme_bw() +
  coord_fixed(ratio = 1)
```


### Puntos con mayor densidad en la esquina inferior izquierda

```{r}
set.seed(semilla)
coords_group <- cbind(long = sample(1:n / n - 0.5 / n)^2, lat = sample(1:n / n - 0.5 / n)^2)
```
```{r class.source = 'fold-hide'}
ggplot(data.frame(coords_group), aes(x = long, y = lat)) +
  geom_point() + 
  theme_bw() +
  coord_fixed(ratio = 1)
```

### Puntos aleatorios de un polígono

```{r results='hide'}
# Cargar polígono
nc <- st_read(system.file("shape/nc.shp", package="sf"))
nc <- st_union(nc)

# Generar localizaciones
set.seed(semilla)
points <- st_sample(nc, size = n)
```
```{r class.source = 'fold-hide'}
ggplot() + 
  geom_sf(data = nc) + 
  geom_sf(data = points) +
  theme_bw()
```

## {.unlisted .unnumbered}

La dependencia espacial entre los puntos se puede definir mediante una estructura de covarianza Matern. La función de correlación Matern tiene dos parámetros: el parámetro de escala $\kappa$ y el parámetro de suavizado $\nu$. Puedes encontrar una explicación detallada de la función de correlación Matern [aquí](https://becarioprecario.bitbucket.io/spde-gitbook/ch-intro.html#sec:matern).

$$
\text{Corr}(d) = \frac{1}{2^{\nu-1}\Gamma(\nu)} (\kappa d)^{\nu} K_{\nu}(\kappa d), \quad \alpha = \nu + \frac{d}{2},
$$
donde $K_{\nu}$ es la función de Bessel modificada y $\Gamma(\cdot)$ es la función Gamma. El rango está definido como $r = \sqrt{8\nu} / \kappa$, aproximadamente la distancia donde la función de covarianza llega a ser cerca de 0.1.

Los hiperparámetros son el parámetro de precisión $\tau$ y el rango $r$, $\theta = (\tau, r)$. El campo latente tiene una varianza marginal de $\frac{1}{\tau}$ y un rango (definido como se mencionó anteriormente) de $r$. Se representan internamente como $(\text{log} \tau, \text{log} r)$.

La matriz de covarianza Matern es

$$
\Sigma_{i,j} = \sigma_u Cor_M(X(s_i), X(s_j))
$$

Para este ejemplo vamos a utilizar las localizaciones generadas aleatoriamente. Observamos que la posición de las localizaciones en los ejes x e y se mueve entre 0 y 200. Los parámetros que vamos a utilizar para la covarianza Matern se eligen en consecuencia. Dada las localizaciones de los puntos (entre 0 y 200) , elegiremos un rango del efecto espacial de 100. Utilizando $\nu = 1$ y a partir de esta realción $r = \sqrt{8\nu} / \kappa$, podemos obtener el valor de $\kappa = 0.02828427$. Le pondremos una varianza de $\sigma^2_u = 2$ al efecto espacial.

Ahora bien, el valor observado en las localizaciones ($_i$), a parte efecto espacial subyacente, tendrá adicionalmente un error de medición ($e_i$) que asumimos independiente y normalmente distribuido: 

$$
y(s_i) = x(s_i) + e_i \quad e_i \sim N(0, \sigma_e^2),
$$
donde $\sigma_e^2$ es el efecto de la pepita. Por eso, tenemos una covarianza $\sigma_e^2 \mathbf{I} + \Sigma$. Definiremos un intercepto de $\beta_0 = 10$ y una semilla (error experimental) de $\sigma^2_e = 0.5$.

```{r}
rango <- 100
nu <- 1
kappa <- sqrt((8*nu))/rango
beta0 <- 10
sigma2e <- 0.5
sigma2u <- 2

dmat <- as.matrix(dist(coords_rand)) # Matriz distancias
```

> ⚠️ Es importante seleccionar un rango adecuado de acuerdo al tamaño y unidades de medida de la zona de estudio.

```{r}
mcor <- ifelse(dmat > 0, besselK(dmat * kappa, nu) * (dmat * kappa)^nu / (gamma(nu) * 2^(nu - 1)), 1)
mcor[1:5, 1:5]

mcov <- sigma2e * diag(nrow(mcor)) + sigma2u * mcor
```

Finalmente, simulamos los valores de nuestra variable respuesta en las localizaciones:

```{r}
R <- chol(mcov) # Descomposición de Cholesky
set.seed(semilla)
y <- beta0 + drop(rnorm(n) %*% R)

datos <- data.frame(long = coords_rand[,1],
                    lat = coords_rand[,2],
                    y = y)
```
```{r class.source = 'fold-hide'}
ggplot(datos, aes(x = long, y = lat)) +
  geom_point(size = y/2) +
  theme_bw() +
  coord_fixed(ratio = 1)
```

## Ajuste del modelo geoestadístico con INLA

Utilizando los datos simulados, vamos a ajustar un modelo geoestadístico con INLA. Para ello, definiremos un modelo SPDE. Dadas $n$ observaciones $y_i$, $i = 1,...n$ en las localizaciones $s_i$, definimos el siguiente modelo geoestadístico sencillo:

$$
\mathbf{y} | \beta_0, \mathbf{u}, \sigma_e^2 \sim N(\beta_0 + \mathbf{Au}, \sigma_e^2),
$$
donde $\beta_0$ es el intercepto, $\mathbf{A}$ es la matriz de proyección, y $\mathbf{u}$ es un campo aleatorio gaussiano espacial. La matriz de proyección $\mathbf{A}$ conecta el campo aleatorio Gaussiano con las localizaciones observadas de los datos.

Al crear un mesh, es crucial asegurarse de que cubra todo el dominio espacial de interés. Podemos definir el siguiente mesh basado en las localizaciones (las localizaciones se dispondrán en los vértices en este caso):
```{r}
mesh <- inla.mesh.2d(coords_rand, max.edge = c(30, 50))
```
```{r class.source = 'fold-hide'}
plot(mesh)
points(coords_rand, col = "red", pch = 16)
```

> ℹ️  Más información obre cómo construir un mesh [aquí](https://becarioprecario.bitbucket.io/spde-gitbook/ch-intro.html#sec:mesh)

El modelo SPDE se puede definir con la función `inla.spde2.matern()`, que utiliza los argumentos `mesh` y `alpha` relacionados con la suavización del parámetro. Esta parametrización es flexible y permite controlar los parámetros definiendo la desviación estándar marginal y el rango. También podríamos definirla utilizando las [PC-priors](https://becarioprecario.bitbucket.io/spde-gitbook/ch-INLA.html#sec:intropc) mediante la función `inla.spde2.pcmatern()`.

Una forma de definir estas priors sería representar el variograma y seleccionar priors para el rango. Como hemos simulado y conocemos el valor, no lo representaremos esta vez. Además, también es interesante realizar un análisis de sensibilidad para observar cómo varían los resultados al utilizar diferentes priors (ya os adelanto que no es particularmente robusto).

```{r}
spde <- inla.spde2.pcmatern(
  # Mesh and smoothness parameter
  mesh = mesh, alpha = 2,
  # P(practic.range < 50) = 0.1
  prior.range = c(50, 0.1),
  # P(sigma > 5) = 0.1
  prior.sigma = c(5, 0.1)) 
```

Esta parte de generar el mesh y el modelo SPDE puede ser un poco compleja. En este [enlace](https://becarioprecario.bitbucket.io/spde-gitbook/ch-intro.html#sec:spde), encontrarás una explicación más detallada.

## Matriz de proyección

El modelo SPDE se define en un mesh de dimensión $m$, mientras que la variable respuesta está definida en $n$ localizaciones. Para establecer una conexión entre los $m$ vértices del mesh y las $n$ localizaciones, empleamos una matriz de proyección $\mathbf{A}$. El valor de cualquier punto se crea proyectando dicho punto sobre un plano formado por el triángulo en el que se encuentra. El valor exacto del punto es la media ponderada de tres pesos asociados a cada vértice.

```{r}
A <- inla.spde.make.A(mesh, loc = coords_rand)
```

La matriz tiene una dimensión igual al número de datos en las localizaciones por el número de vértices del mesh:
```{r}
dim(A)
```

## Ajuste del modelo

Para ajustar un modelo SPDE en INLA, primero debemos organizar los datos en un stack. Esta función permite ordenar los elementos importantes para definir un modelo SPDE. Los elementos clave del stack son: una lista con los vectores de datos, una lista con las matrices de proyección y una lista con los efectos.

```{r}
stack <- inla.stack(
  data = list(y = datos$y),
  A = list(A, 1),
  effects = list(i = 1:spde$n.spde,
                 beta0 = rep(1, nrow(datos))),
  tag = "est"
)
```

Al ajustar el modelo, debemos eliminar el intercepto de la fórmula e incluirlo como una covariable para que todos los efectos se incluyan en la matriz de proyección.

```{r}
res <- inla(y ~ 0 + beta0 + f(i, model = spde),
            data = inla.stack.data(stack),
            control.predictor = list(A = inla.stack.A(stack)))
```

Recordemos que al simular, definimos los siguientes parámetros:

- $\beta_0$ = 10
- $\sigma^2_e$ = 0.5
- $\sigma^2_u$ = 2
- Rango = 100
- $\nu$ = 1

Y observamos que podemos recuperar los parámetros definidos:

```{r}
# Intercepto
res$summary.fixed

# Hiperparámetros
res$summary.hyperpar

# Convertimos la precisión en desviación
post.se <- inla.tmarginal(function(x) sqrt(1 / exp(x)),
                          res$internal.marginals.hyperpar[[1]])
inla.emarginal(function(x) x, post.se)
inla.hpdmarginal(0.95, post.se)
```
```{r class.source = 'fold-hide'}
plot(post.se, type = "l", xlab = "st. deviation", 
     ylab = "density", main = "Standard deviation")
```

## Proyección del campo aleatorio y predicciones

Un objetivo principal al trabajar con modelos espaciales es visualizar el campo aleatorio. Utilizando la función `inla.mesh.projector()`, generaremos una matriz de proyección sobre un grid de puntos que cubre nuestro mesh.

```{r}
grid.projector <- inla.mesh.projector(
  mesh,
  xlim = c(0, 200), ylim = c(0, 200),
  dims = c(101, 101)
)
```

A continuación, podemos obtener la media y desviación a posteriori del efecto espacial basándonos en la idea del mesh, donde cada punto se interpola utilizando esa matriz de proyección y para cada punto (fila de la matriz), tenemos el peso de los tres vértices del triángulo del mesh donde se encuentra:

```{r}
prd0.m <- inla.mesh.project(grid.projector,
                            res$summary.random$i$mean)
prd0.s <- inla.mesh.project(grid.projector,
                            res$summary.random$i$sd)
```

Por otro lado, otra cantidad de interés es el valor esperado en las localizaciones que no hemos observado. Considerando que
$$
\mathbf{y} \sim N(\mu = \mathbf{1}\beta_0 + \mathbf{Au}, \sigma_ e^2 \mathbf{I}),
$$
vamos a querer predecir la media y desviación en diferentes localizaciones, es decir, la distribución a posteriori de $\mu$.

Para ello, debemos crear un escenario de predicción. Crearemos dos stacks, uno que represente los datos observados y otro las predicciones (con NA en la respuesta). Estos stacks se juntarán en un mismo stack.

```{r}
stack_pred <- inla.stack(
  data = list(y = NA),
  A = list(grid.projector$proj$A, 1),
  effects = list(i = 1:spde$n.spde,
                 beta0 = rep(1, nrow(grid.projector$proj$A))),
  tag = "pred"
)

stack_all <- inla.stack(stack, stack_pred)

res.pred <- inla(y ~ 0 + beta0 + f(i, model = spde),
                 data = inla.stack.data(stack_all),
                 control.predictor = list(A = inla.stack.A(stack_all),
                                          compute = TRUE),
                 control.mode = list(theta = res$mode$theta,
                                     restart = FALSE),
                 quantiles = NULL)
```

Obtenemos los índices de los valores predichos:

```{r}
igr <- inla.stack.index(stack_all, 'pred')$data
```
```{r class.source = 'fold-hide'}
par(mfrow = c(2, 2))
image(x = grid.projector$x, y = grid.projector$y, z = prd0.m, main = "Media efecto espacial")
image(x = grid.projector$x, y = grid.projector$y, z =  matrix(res.pred$summary.fitted.values$mean[igr], 101), main = "Respuesta esperada")
image(x = grid.projector$x, y = grid.projector$y, z = prd0.s, main = "SD efecto espacial")
image(x = grid.projector$x, y = grid.projector$y, z =  matrix(res.pred$summary.fitted.values$sd[igr], 101), main = "SD mu")
```

# Datos Binomiales(Práctica 7 MJB) {.tabset}

Vamos a analizar un banco de datos que contiene las *defunciones por cáncer de estómago* en 84 ciudades de *Missouri*, además de la población de cada una de ellas.

```{r}
#Cargamos los datos
load("datos/meta (1).Rdata")
datos_cancer <- cbind(N, y)
datos_cancer <- as.data.frame(datos_cancer)

#Resumen de los datos
summary(datos_cancer)

```

- **Variable respuesta**: $Y_i$ es la variable que nos dice el número de defunciones por cáncer respecto del total de la población. ($i = 1, ..., 84$)

- En este caso no disponemos de ninguna covariable que nos ayude a explicar la distribución de nuestro modelo.

- Deseamos estimar la tasa de mortalidad (por 100000 habitantes) para cada una de las ciudades, por lo que consideramos el siguiente modelo estadístico:

$$
Y_i \sim Bin(\pi_i,n_i), \quad i = 1, ..., 84
$$
- Utilizamos la transformación logit para relacionar el predictor lineal con la respuesta media:

$$
log \Big( \frac{\pi_i}{1 - \pi_i} \Big) = logit(\pi_i) = a_i
$$
- El predictor lineal consiste únicamente en el efecto a, el cual modelizaremos como efecto aleatorio normal, ya que al modelizarlo como efecto fijo de cada ciudad o como efecto fijo común perderíamos información relevante sobre la muestra.

## Bayesiano con INLA

```{r}
#Calculamos la tasa esperada para comparar los resultados
pi <- datos_cancer$y/datos_cancer$N

#Introducimos el efecto aleatorio
mod_inla_cancer <- inla(y ~ 1+f(pi, model = "iid"),
     family = "binomial",
     Ntrials = N,
     #El argumento Ntrials es necesario en la binomial
     
     control.compute = list(dic = TRUE, waic = TRUE, return.marginals.predictor = TRUE),
     #Estos argumentos nos servirán para la comparación de modelos
     #El argumento return.marginals nos ayudará a graficar pi
     control.predictor = list(compute = TRUE),
     data = datos_cancer)

summary(mod_inla_cancer)
```

El intercept aparece por defecto en el modelo con la transformación presente en el link (en este caso logit), los fitted values aparecen en escala original.

Ahora utilizaremos un tipo de prior distinta, muy utilizada en la modelización con INLA, llamadas en su conjunto *Penalized Complexity Priors* o PC-priors.

- Estas priors penalizan la distancia hacia un modelo base al menos que haya evidencia en su contra (*Princpio de Parsimonia*).

- Se definen estableciendo probabilidades sobre los parámetros del modelo en la escala adecuada.

**Ejemplo**

Para la precisión($\tau$) se utilizan los parámetros u y $\alpha$, tal que:

$$
Prob(\sigma >u)= \alpha
$$
En este caso utilizaremos una PC prior para la precisión de nuestro efecto aleatorio.

```{r}
#Probando con diferentes priors
mod_inla_cancer_2 <- inla(y ~ 0+f(pi, model = "iid", hyper = list(
prec = list(
prior = "pc.prec",
param = c(5, 0.01)))),
     family = "binomial",
     Ntrials = N,
#El argumento Ntrials es necesario en la binomial

     control.compute = list(dic = TRUE, waic = TRUE, return.marginals.predictor = TRUE),
#Estos argumentos nos servirán para la comparación de modelos
     #El argumento return.marginals nos ayudará a graficar pi
     control.predictor = list(compute = TRUE),
     data = datos_cancer)

summary(mod_inla_cancer_2)
```

## Bayesiano con WinBUGS

```{r, eval=FALSE}
datos_cancer_winb <- list(y = y, N = N, n = length(y))
p.star <- sum(y)/sum(N)
logit.p.star <- log(p.star/(1 - p.star))
mod_cancer_winb <- function() {
  for (i in 1:n) {
    y[i] ~ dbin(pi[i], N[i])
    logit(pi[i]) <- mu + theta[i]
    theta[i] ~ dnorm(0, tau)
    # Probabilidad de exceso de riesgo
    
    p[i] <- step(theta[i])
    # tasa por 100.000 habitantes
    
    tasa[i] <- pi[i] * 1e+05
  }
  #distribuciones iniciales
  
  mu ~ dflat()
  tau <- pow(sd.theta, -2)
  sd.theta ~ dunif(0, 100)
}
# Modelo efectos aleatorios

iniciales_cancer_winb <- function() {
  list(mu = rnorm(1, logit.p.star, 1), theta = rnorm(84, 0, 1), sd.theta = runif(1, 0, 2))
}

param <- c("pi")
set.seed(123)
resul_mod_cancer_winb <- bugs(data = datos_cancer_winb, inits = iniciales_cancer_winb, parameters = param, model = mod_cancer_winb,
                n.burnin = 1000, n.iter = 5000, bugs.directory = "C:/Users/juanv/OneDrive/Escritorio/Master Bioestadística/Modelización avanzada/Modelos jerárquicos Bayesianos/Prácticas/WinBUGS14")

save(resul_mod_cancer_winb, file = "modelos/mcmc_cancer.RData")

head(round(resul_mod_cancer_winb$summary,6))

```
```{r}
load("modelos/mcmc_cancer.RData")
# Resumen de los resultados
head(round(resul_mod_cancer_winb$summary, 6))
```

# {.unlisted .unnumbered}

**Comparación**

A continuación, compararemos los resultados de los modelos, en concreto, la proporción de enfermos de cáncer de las 6 primeras ciudades, a modo de muestra:

```{r class.source = 'fold-hide'}
# Visualización de resultados
 
#Extraemos las proporciones de cada ciudad

#INLA
pi_inla <- mod_inla_cancer$marginals.fitted.values
pi_inla_2 <- mod_inla_cancer_2$marginals.fitted.values

#WinBUGS
pi_winb <- resul_mod_cancer_winb$sims.list$pi
winb_cancer_list <- list()
for (i in 1:84) {
winb_cancer_list[[i]] <- pi_winb[, i]  
}

#Representamos conjuntamente las distribuciones de los 3 modelos
plist_2 <- list()
for (i in 1:6){
  pgg <- ggplot() +
    geom_density(data = data.frame(x = winb_cancer_list[[i]]), aes(x), linewidth=1, color = "#4FA3AB", linetype = "dashed") +
    geom_line(data = data.frame(inla.smarginal(pi_inla[[i]])), aes(x, y), linewidth = 1, color = "#F6733A", linetype = "dashed") +
    geom_line(data = data.frame(inla.smarginal(pi_inla_2[[i]])), aes(x, y), linewidth = 1, color = "#00FF00", linetype = "dashed")
    ggtitle(names(pi_inla)[i]) +
    theme_bw()
  
  plist_2[[i]] <- pgg
}

n_2 <- length(plist_2)
nCol_2 <- ceiling(sqrt(n_2))
do.call("grid.arrange", c(plist_2, ncol=nCol_2, top = "WinBUGS: Azul, INLA: Naranja, INLA PC: Verde"))
```

Podría parecer en este caso que las distribuciones a posteriori de Inla y WinBUGS no son todo lo parecidas que deberían, pero a una escala tan pequeña se pueden dar estas diferencias. 

Destaca que las distribuciones a posteriori de WinBUGS son más apuntadas, seguramente porque es un método exacto, frente a una aproximación como INLA.

En cuanto a los 2 modelos de INLA con diferentes priors, vemos que la diferencia es insignificante.

A continuación observamos los estimadores puntuales de las distribuciones estimadas en los modelos bayesianos.

```{r}
params_2 <- cbind(resul_mod_cancer_winb$summary[c(1:9), c(1, 3, 7)],
          mod_inla_cancer$summary.fitted.values[c(1:9), c(1, 3, 5)],
mod_inla_cancer_2$summary.fitted.values[c(1:9), c(1, 3, 5)])
colnames(params_2) <- paste0(rep(c("WinBUGS_", "INLA 1(no PC)_", "INLA 2(PC)_"), each = 3), c("est/mean", "2.5%", "97.5%"))

header_df_2 <- tibble(key = colnames(params_2)) %>% 
  separate(col = key, into = c("Group1", "Group2"), sep = "_", remove = FALSE, fill = "left")

params_2 %>% 
  mutate(across(where(is.numeric), round, 6)) %>% 
  rownames_to_column("Coefficients") %>% 
  flextable() %>% 
  set_header_df(mapping = header_df_2, key = "key") %>% 
  merge_h(part = "header") %>% 
  theme_booktabs() 
  

```
Como se puede observar, las diferencias son ínfimas entre todos los modelos bayesianos.

# Modelo Poisson con Random Walk (Tarea 8 MJB) {.tabset}

En este caso nuestro banco de datos contiene información sobre la mortalidad por enfermedades congénitas en hombres en España.

Disponemos del número de defunciones mensuales por esta
causa durante el periodo 1999-2008.

```{r}
load("datos/congenitas (1).Rdata")

#Añadimos una variable con los ID ordenados para poder modelizar el random walk
tiempo <- seq(1, 120)
datos_mort <- as.data.frame(cbind(tiempo, mort))
```

- **Variable respuesta**: $Y_i$ es la variable que nos dice el número de defunciones mensuales por enfermedades congénitas ($i = 1, ..., 120$)

- En este caso no disponemos de ninguna covariable que nos ayude a explicar la distribución de nuestro modelo.

- Deseamos estimar el número de defunciones esperadas, por lo que planteamos el siguiente modelo:

$$
Y_i \sim Poisson(\lambda_i), \quad i = 1, ..., 200
$$
Donde $\lambda_i$ representa la tasa de ocurrencia de la muerte por esta causa en cada mes estudiado.

- Utilizamos la transformación log para relacionar el predictor lineal con la respuesta media:

$$
log(\lambda_i) = a_i
$$
Un modelo de efectos aleatorios sería lo adecuado para la modelización, ya que las defunciones en todos los meses deberían seguir la misma distribución.

Pero, además de esto, tiene sentido que las observaciones sean dependientes entre sí, en concreto las de meses cercanos, por lo que utilizaremos Random Walk para modelizar esta dependencia.

El efecto aleatorio dependiente $a_i$ seguirá una distribución:

$$
a_i \sim Normal(\mu_i,\sigma), \quad i = 1, ..., 200
$$
Con predictor lineal:

$$
\mu_i= a_{i-1}
$$

- Para el *Random Walk de primer orden*, y:

$$
\mu_i= a_{i-1}+(a_{i-1}-a_{i-2})
$$
- Para el *Random Walk de segundo orden*

## Bayesiano con  INLA

```{r}
#Especificación del random walk de primer orden
mod_mort_inla_rw1 <- inla(mort ~ f(tiempo, model = "rw1"),
         family = "poisson",
         control.compute = list(dic = TRUE, waic = TRUE, return.marginals.predictor = TRUE),
         control.predictor = list(compute = TRUE),
         data = datos_mort)
summary(mod_mort_inla_rw1)

#Especificación del random walk de segundo orden
mod_mort_inla_rw2 <- inla(mort~f(tiempo, model = "rw2"),
         family = "poisson",
         control.compute = list(dic = TRUE, waic = TRUE, return.marginals.predictor = TRUE),
         control.predictor = list(compute = TRUE),
         data = datos_mort)
summary(mod_mort_inla_rw2)
```

## Bayesiano con WinBUGS
```{r, eval=FALSE}
mod_mort_winb_rw1 <- function() {
  for (i in 1:120) {
    mort[i] ~ dpois(media[i])
    log(media[i]) <- a[i]
  }
  a[1] ~ dflat()
  for (i in 2:120) {
    a[i] ~ dnorm(a[i - 1], tau.a)
  }
  tau.a <- pow(sd.a, -2)
  sd.a ~ dunif(0, 100)
}

# Llamada al modelo RW1
datos_mort <- list(mort = mort)
inits_mod_mort_winb_rw1 <- function() {
  list(a = rnorm(120), sd.a = runif(1, 0, 5))
}
param_3 <- c("media", "sd.a")
# Elevamos el número de iteraciones habituales ya que la convergencia de
# este modelo resulta problematica

resul_mod_mort_winb_rw1 <- bugs(data = datos_mort, inits = inits_mod_mort_winb_rw1, param = param_3, model.file = mod_mort_winb_rw1,
                  n.iter = 10000, n.burnin = 2000, bugs.directory = "C:/Users/juanv/OneDrive/Escritorio/Master Bioestadística/Modelización avanzada/Modelos jerárquicos Bayesianos/Prácticas/WinBUGS14")
head(round(resul_mod_mort_winb_rw1$summary, 4))

save(resul_mod_mort_winb_rw1, file = "modelos/mcmc_mort_rw1.RData")

# Modelo Random Walk de segundo orden
mod_mort_winb_rw2 <- function() {
for (i in 1:120) {
mort[i] ~ dpois(media[i])
log(media[i]) <- a[i]
}
a[1] ~ dflat()
a[2] ~ dflat()
for (i in 3:120) {
a[i] ~ dnorm(media.a[i], tau.a)
media.a[i] <- a[i - 1] + (a[i - 1] - a[i - 2])
}
tau.a <- pow(sd.a, -2)
sd.a ~ dunif(0, 100)
}
inits_mod_mort_winb_rw2 <- function() {
list(a = rnorm(120, log(mean(mort), 0.1)), sd.a = runif(1, 0, 5))
}
resul_mod_mort_winb_rw2 <- bugs(data = datos_mort, inits = inits_mod_mort_winb_rw2, param = param_3, model.file = mod_mort_winb_rw2,
n.iter = 5e+05, n.burnin = 50000,bugs.directory = "C:/Users/juanv/OneDrive/Escritorio/Master Bioestadística/Modelización avanzada/Modelos jerárquicos Bayesianos/Prácticas/WinBUGS14")
head(round(resul_mod_mort_winb_rw2$summary, 2))

save(resul_mod_mort_winb_rw2, file = "modelos/mcmc_mort_rw2.RData")

```
```{r}
load("modelos/mcmc_mort_rw1.RData")
# Resumen de los resultados
head(round(resul_mod_mort_winb_rw1$summary, 4))

load("modelos/mcmc_mort_rw2.RData")
# Resumen de los resultados
head(round(resul_mod_mort_winb_rw1$summary, 4))
```

La convergencia de los parámetros del random walk 2 no es buena incluso con un elevado número de interacciones, pero, por ahorrarnos tiempo, tomaremos estos valores de ejemplo, ya que un modelo con más interacciones tardaría demasiado.

# {.unlisted .unnumbered}

**Comparación**

Representamos el número de hombres afectados por enfermedades congénitas en los 6 primeros meses.

```{r class.source = 'fold-hide'}
# Visualización de resultados
 
#Extraemos las proporciones de cada ciudad

#INLA
pois_inla_1 <- mod_mort_inla_rw1$marginals.fitted.values
pois_inla_2 <- mod_mort_inla_rw2$marginals.fitted.values

#WinBUGS
pois_winb1 <- resul_mod_mort_winb_rw1$sims.list$media
pois_winb2 <- resul_mod_mort_winb_rw2$sims.list$media
winb_mort1_list <- list()
for (i in 1:120) {
winb_mort1_list[[i]] <- pois_winb1[, i]  
}
winb_mort2_list <- list()
for (i in 1:120) {
winb_mort2_list[[i]] <- pois_winb2[, i]  
}

#Representamos conjuntamente las distribuciones de los 3 modelos
plist_3 <- list()
for (i in 1:6){
  pgg <- ggplot() +
    geom_density(data = data.frame(x = winb_mort1_list[[i]]), aes(x), linewidth=1, color = "#4FA3AB", linetype = "dashed") +
    geom_density(data = data.frame(x = winb_mort2_list[[i]]), aes(x), linewidth=1, color = "#FF0000", linetype = "dashed") +
    geom_line(data = data.frame(inla.smarginal(pois_inla_1[[i]])), aes(x, y), linewidth = 1, color = "#F6733A", linetype = "dashed") +
    geom_line(data = data.frame(inla.smarginal(pois_inla_2[[i]])), aes(x, y), linewidth = 1, color = "#00FF00", linetype = "dashed")
    ggtitle(names(pois_inla_1)[i]) +
    theme_bw()
  
  plist_3[[i]] <- pgg
}

n_3 <- length(plist_3)
nCol_3 <- ceiling(sqrt(n_3))
do.call("grid.arrange", c(plist_3, ncol = nCol_3, top = "WinBUGS RW1: Azul,WinBUGS RW2: Rojo INLA RW1: Naranja, INLA RW2: Verde"))
```

En el gráfico observamos que los parámetros de los modelos que incluyen una dependencia tipo *Random walk* tienen intervalos de credibilidad cada vez más pequeños, apuntandose sus gráficas progresivamente.

Las primeras observaciones tienen menos credibilidad en los modelos con RW porque no tienen observaciones anteriores de las que extraer información.

Los intervalos de credibilidad disminuyen hasta que se estabilizan, antes en el RW1 que en el RW2. Esto es porque el RW2 incluye información de las 2 observaciones anteriores(más credibilidad), mientras que el RW1 sólo incluye información de la observación inmediatamente anterior. 

Las diferencias entre INLA y WinBUGS son contradictorias:

- En los modelos RW1, INLA presenta mayor credibilidad que Winbugs.
- En los modelos RW2 es WinBUGS quien presenta mayor credibilidad.

En el ejemplo anterior veíamos que los intervalos de WinBUGS eran más precisos seguramente por ser un método exacto y no una aproximación, pero ahora, con un modelo más complejo y problemas de convergencia vemos que no siempre es así.


```{r}
params_3 <- cbind(resul_mod_mort_winb_rw1$summary[c(1:9), c(1, 3, 7)],
            resul_mod_mort_winb_rw2$summary[c(1:9), c(1, 3, 7)],      
          mod_mort_inla_rw1$summary.fitted.values[c(1:9), c(1, 3, 5)],
mod_mort_inla_rw2$summary.fitted.values[c(1:9), c(1,3,5)])
colnames(params_3) <- paste0(rep(c("WinBUGS RW1_", "WinBUGS RW2_", "INLA RW1_", "INLA RW2_"), each = 3), c("est/mean", "2.5%", "97.5%"))

header_df_3 <- tibble(key = colnames(params_3)) %>% 
  separate(col = key, into = c("Group1", "Group2"), sep = "_", remove = FALSE, fill = "left")

params_3 %>% 
  mutate(across(where(is.numeric), round, 1)) %>% 
  rownames_to_column("Coefficients") %>% 
  flextable() %>% 
  set_header_df(mapping = header_df_3, key = "key") %>% 
  merge_h(part = "header") %>% 
  theme_booktabs() 

```

Estos resultados numéricos confirman todo lo comentado en la observación gráfica.


# Tarea 6 - Datos Binomiales 2 (Tarea Final MJB) {.tabset}


Nos encontramos ante datos epidemiológicos de tipo veterinario. Las observaciones corresponden a las distintas visitas que se han llevado a cabo a distintas granjas, en las que se han tomado distintas muestras de vacas. En las muestras vacunas se ha valorado la presencia de pleuroneumonía bovina contagiosa, una enfermedad contagiosa que concluye en el sacrificio del animal. 
Por tanto:

- Variable respuesta: número de incidentes en cada muestra m.
- El parámetro de interés será la probabilidad de presencia de la enfermedad en la vaca.

Se propone resolver los apartados utilizando INLA para complementar el ejercicio propuesto a resolver en la asignatura de MJB usando métodos MCMC (en este caso, WinBUGS).

1. Modelizar la relación entre la probabilidad de encontrar animales infectados (incidencia de la enfermedad) y el periodo de estudio. Considera para este estudio la variable periodo como una variable numérica y considera su efecto de forma lineal dentro del predictor lineal correspondiente. ¿Encuentras que el periodo ha tenido un efecto significativo sobre la incidencia de la enfermedad? ¿De qué forma influye?

Se plantea un modelo en el que la variable respuesta va a seguir una distribución binomial (número de incidentes de una muestra total), en el que la probabilidad de que haya presencia de la enfermedad ($\pi$) se relacionará con el predictor lineal mediante el *logit*:

$$ incidentes_{i} \sim Binomial (\pi_{i},muestra_{i})$$,
$$ logit(\pi_{i})= \beta_{0}+\beta_{1} periodo_{i}$$

```{r}
#cargamos los datos
load("./datos/EpiGranjas.Rdata")
granjas <- EpiGranjas
```



## Modelo 1 en WinBUGS

Se propone el modelo en bayesiano, dándole distribuciones previas no informativas a los coeficientes (no hay información previa). La variable periodo se mantiene como variable numérica en este apartado.

```{r,eval=FALSE}

granjas$periodo <- as.numeric(granjas$periodo)



modgranjas1 <- function(){

  # Verosimilitud

  for (i in 1:n) {

    incidentes[i]~ dbin(p[i],muestra[i])

    #predictor lineal

    logit(p[i]) <- beta0+beta1*periodo[i]

  }

  #distribuciones iniciales

  beta0 ~ dflat()

  beta1 ~ dflat()
  
  Pbeta1 <- step(beta1)

}

datosgranjas1<- list(n=dim(granjas)[1], incidentes=granjas$incidentes, muestra=granjas$muestra, periodo=granjas$periodo)

pargranjas1 <- list("beta0","beta1","Pbeta1")

init.granjas1 <- function(){

  list(beta0 = rnorm(1),beta1=rnorm(1))

}

res.granjas1 <- bugs(data=datosgranjas1,inits=init.granjas1,par=pargranjas1,model=modgranjas1)

save(res.granjas1,file="./modelos/res.granjas1.RData")
```


```{r}
load("./modelos/res.granjas1.RData")
res.granjas1$summary
res.granjas1$DIC
```

Viendo el resumen del modelo, podemos concluir que el periodo tiene un efecto negativo significativo en la incidencia de la enfermedad. Por cada aumento de una unidad en el periodo, los *odds* de la incidencia se multipilica por exp(-0.55), con un intervalo de credibilidad al 95% de beta1 de (-0.78,-0.34). Se observa que la convergencia del modelo es óptima (tanto los Rhats, como las iteraciones efectivas son aceptables para los coeficientes).



## Modelo 1 en INLA

Se plantea lo mismo, pero en INLA. Al ser una binomial, se añade "Ntrials=muestra" como argumento de la función *inla()* para incluir la m en el modelo. Hay que tener en cuenta que las previas del modelo en WinBUGS y en INLA no son las mismas (en INLA, las previas, en este caso, las automatiza la función usada), por lo que comparar entre un modelo y otro no es del todo correcto.

```{r}
granjas$periodo <- as.numeric(granjas$periodo)
m1.granjas <- inla(formula=incidentes~1+periodo,family="binomial", Ntrials=granjas$muestra,

quantiles = c(0.025, 0.975), control.compute = list(dic = TRUE,waic=T, cpo=T),data = granjas)

```


```{r}
m1.granjas$summary.fixed

m1.granjas$dic$dic
```
De todas formas, en estos modelos tan sencillos no debería variar mucho de uno a otro. Así, vemos que el efecto del periodo tiene un efecto negativo y significativo, con un $\beta_{1}$= -0.57 y un intervalo de credibilidad al 95% de (-0.80,-0.35).

# {.tabset}


2. Sospechamos que la relación periodo-incidencia pudiera tener una relación tipo no lineal. Para
evaluar esta hipótesis considera la variable periodo como categoríca, empleando como valor de
referencia el primer periodo. ¿Encuentras diferencias significativas entre el primer periodo
y los restantes? ¿Qué estrategia de modelización te parece más adecuada para la variable
periodo, su tratamiento como variable numérica o categórica?


Se propone el mismo modelo anterior, pero considerando la variable explicativa referida al periodo como factor (de 4 niveles):

$$ incidentes_{i} \sim Binomial (\pi_{i},muestra_{i})$$,
$$ logit(\pi_{i})= \beta_{0}+\beta_{1} periodo_{2}+ \beta_{2}periodo_{3}+\beta_{3}periodo_{4} $$

## Modelo 2 en WinBUGS


Se plantea el modelo:

```{r, eval=FALSE}

modgranjas2 <- function(){

  #Verosimilitud
for (i in 1:n) {
    incidentes[i]~ dbin(p[i],muestra[i])
    #predicción lineal
     logit(p[i]) <- beta0+beta1[periodo[i]]
  } 

  #distribuciones iniciales y restricción Corner:

  beta0 ~ dflat()

  beta1[1]<- 0

  beta1[2] ~ dflat()

  beta1[3] ~ dflat()

  beta1[4] ~ dflat()

  Pbeta12 <- step(beta1[2])

  Pbeta13 <- step(beta1[3])

  Pbeta14 <- step(beta1[4])

}
datosgranjas2<- list(n=dim(granjas)[1], incidentes=granjas$incidentes, muestra=granjas$muestra, periodo=granjas$periodo)

pargranjas2 <- list("beta0","beta1","Pbeta12","Pbeta13","Pbeta14")

init.granjas2 <- function(){
  list(beta0 = rnorm(1),beta1=c(NA, rnorm(3)))
}
res.granjas2 <- bugs(data=datosgranjas2,inits=init.granjas2,par=pargranjas2,model=modgranjas2)
save(res.granjas2,file="./modelos/res.granjas2.RData")


```

```{r}
load("./modelos/res.granjas2.RData")
res.granjas2$summary
res.granjas2$DIC; res.granjas1$DIC
```

Este segundo modelo también cumple con una buena convergencia de las cadenas markovianas. Se ha aplicado una restricción tipo corner en la variable "periodo".
Observando los resultados del modelo, podemos decir que sí hay diferencias significativas  entre el primer periodo (referencia) y los demás. Respecto al periodo 1, los demás periodos tienen un efecto negativo (a mayor periodo, mayor efecto negativo). Parece que estudiar los periodos de tiempo como un factor es mejor manera de estudiar la relación respecto a la incidencia de la enfermedad. Además, fijándonos en el criterio DIC, mejora un poco el ajuste respecto al primer modelo.


## Modelo 2 en INLA.

Se plantea el mismo modelo usando INLA. Se observan prácticamente los mismos resultados comentados. El criterio DIC para comparar el ajuste se reduce respecto al modelo anterior.

```{r}
granjas$periodo <- as.character(granjas$periodo)

m2.granjas <-inla(formula=incidentes~1+periodo,family="binomial", Ntrials=granjas$muestra,
quantiles = c(0.025, 0.975),
control.compute = list(dic = TRUE,waic=T, cpo=T),
data = granjas)

summary(m2.granjas)
m2.granjas$dic$dic; m1.granjas$dic$dic
```


# {.tabset}

3. Los datos del banco de datos corresponden a distintas granjas, factor que hemos ignorado hasta ahora en la modelización. Contempla la modelización del efecto de la granja en el modelo que te parezca más oportuno de los que hayas ajustado hasta ahora.

Se plantea un modelo en el que se incluye cada granja (hay 15 en total) como un efecto aleatorio. Así se conseguirá que todas las granjas compartan información (seguirán la misma distribución).

Así,

$$ incidentes_{i} \sim Binomial (\pi_{i},muestra_{ij}),      i=1,..., 56; j=1,...,15$$, 
donde $\pi_{i}$ se relaciona mediante el *logit* con el predictor lineal:
$$ logit(\pi_{i})= \beta_{0}+\beta_{1} periodo_{2}+ \beta_{2}periodo_{3}+\beta_{3}periodo_{4} + granja_{j} $$

## Modelo 3 en WinBUGS.


```{r,eval=FALSE}

granjas$periodo <- as.numeric(granjas$periodo);granjas$granja <- as.numeric(granjas$granja)

modgranjas3 <- function(){
  for (i in 1:n){
  incidentes[i] ~ dbin(p[i], muestra[i])
  logit(p[i]) <- beta0 + beta1[periodo[i]] + beta2[granja[i]]
  }

  beta0 ~ dflat()
  beta1[1] <- 0
  for (j in 2:4){
  beta1[j] ~ dflat()
  Pbeta1[j] <- step(beta1[j])
  }

  for (k in 1:15){
  beta2[k] ~ dnorm(0, tau.a)
  Pbeta2[k] <- step(beta2[k])
  }

  for (l in 1:15){
  Pgranjamayor[l] <- step(beta2[l]-mean(beta2[]))
  }
  tau.a <- pow(sd.a,-2)
  sd.a ~ dunif(0, 100)
  a ~ dnorm(0, tau.a)
}

inic3 <- function(){
  list(beta0=rnorm(1,0,10), beta1=c(NA, rnorm(3,0,10)), beta2=rnorm(15,0,10), sd.a=runif(1))
}

datosgranjas3 <- list(incidentes=granjas$incidentes, n=dim(granjas)[1], muestra=granjas$muestra, periodo=granjas$periodo,granja=granjas$granja)

param3 <- c("beta0","beta1","Pbeta1","beta2","Pbeta2","Pgranjamayor","sd.a")

res.granjas3 <- bugs(data = datosgranjas3, inits = inic3, parameters = param3, model = modgranjas3, 

             n.iter = 10000, n.burnin = 4000,  debug = T,bugs.seed=1)

save(res.granjas3,file="./modelos/res.granjas3.RData")


```

```{r}
load("./modelos/res.granjas3.RData")
head(res.granjas3$summary)
res.granjas3$DIC
```

Basándonos en el criterio DIC, el cual evalúa la complejidad y el ajuste del modelo, vemos que el tercer modelo (efecto aleatorio de las granjas) tiene un DIC menor que el del modelo del apartado anterior (187 frente a 208). Por tanto, es bastante aconsejable incluir este efecto, ya que conseguimos considerablemente mejorar el ajuste del modelo.

## Modelo 3 en INLA

Al incluir un efecto aleatorio, el campo latente gaussiano se completará con dicho efecto aleatorio de la granja, con su precisión ($\tau_{granja_{j}}$) como hiperparámetro:

$$granja_{j} \sim N(0,\tau_{granja_{j}})$$
Así, se añade el efecto aleatorio dentro de la función INLA() con el parámetro model="iid". Se ha usado una PC prior (Penalized Complexity Prior) como previa para el hiperparámetro. 

```{r}
granjas$periodo <- as.character(granjas$periodo);granjas$granja <- as.character(granjas$granja)

m3.granjas <- inla(formula=incidentes~1+periodo+f(granja,model="iid",hyper = list(prec = list(prior = "pc.prec",
param = c(5, 0.01)))),family="binomial", Ntrials=granjas$muestra,

quantiles = c(0.025, 0.975),

control.compute = list(dic = TRUE,waic=T, cpo=T),

data = granjas)

summary(m3.granjas); m3.granjas$dic$dic
```

Se observan, al igual que con BUGS, resultados notablemente mejores al incluir el efecto aleatorio, con un DIC de 187. 

# {.unlisted .unnumbered}

## Comparación de modelos para el mejor ajuste (INLA)

A modo resumen, se comparan en la siguiente tabla los criterios DIC para el ajuste y el WAIC y LCPO para estudiar la capacidad predictiva de los tres modelos:

```{r}

seleccion.granjas.inla <- data.frame(DIC  = c(m1.granjas$dic$dic, m2.granjas$dic$dic, m3.granjas$dic$dic),

                        WAIC = c(m1.granjas$waic$waic, m2.granjas$waic$waic, m3.granjas$waic$waic),

                        LCPO = c(-mean(log(m1.granjas$cpo$cpo)),

                                 -mean(log(m2.granjas$cpo$cpo)),

                                 -mean(log(m3.granjas$cpo$cpo))))

rownames(seleccion.granjas.inla)<- c("M1: periodo (num)", "M2: periodo (factor)", "M3: periodo + granja (ea)")

seleccion.granjas.inla


```

Como se ha ido comprobando, se concluye que el modelo en el que incluimos el efecto aleatorio de cada granja muestreada funciona mejor en base al ajuste y la predicción.



